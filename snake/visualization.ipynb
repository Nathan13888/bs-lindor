{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea547e20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08e7f5-9674-4f7f-8f4d-ef05b45cb10b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from bs_gym.gymbattlesnake import BattlesnakeEnv\n",
    "from a2c_ppo_acktr.storage import RolloutStorage\n",
    "\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "from policy import SnakePolicyBase, create_policy\n",
    "from utils import n_opponents, device\n",
    "from utils import PathHelper, plot_graphs\n",
    "from performance import check_performance # TODO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a297b1f-a5a6-4590-8d7b-c1728b6d1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u = PathHelper()\n",
    "rollouts = None\n",
    "policy = None\n",
    "policies = None\n",
    "\n",
    "# TODO:\n",
    "n_envs = 1\n",
    "n_steps = 600\n",
    "CPU_THREADS = 6\n",
    "\n",
    "\n",
    "def setup_rollouts() -> BattlesnakeEnv:\n",
    "    global rollouts\n",
    "    tmp_env = BattlesnakeEnv(n_threads=2, n_envs=n_envs)\n",
    "\n",
    "    rollouts = RolloutStorage(n_steps,\n",
    "                            n_envs,\n",
    "                            tmp_env.observation_space.shape,\n",
    "                            tmp_env.action_space,\n",
    "                            n_steps)\n",
    "    tmp_env.close()\n",
    "\n",
    "    return tmp_env\n",
    "\n",
    "# TODO: refactor to utils\n",
    "def setup_policy(tmp_env, model_path=None):\n",
    "    global device\n",
    "\n",
    "    policy = create_policy(tmp_env.observation_space.shape, tmp_env.action_space, SnakePolicyBase)\n",
    "    if model_path is not None:\n",
    "        policy.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    policy.to(device)\n",
    "    policy.eval()\n",
    "\n",
    "    # TODO: load multiple models, load state dict into policies\n",
    "    return policy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8002e-4bdc-4591-8888-09c4676c20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_offset(obs):\n",
    "    for x in range(23):\n",
    "        for y in range(23):\n",
    "            if obs[0][5][x][y] == 1:\n",
    "                return x, y\n",
    "\n",
    "\n",
    "def obs_to_frame(obs, width=11, height=11):\n",
    "    output = np.zeros((width, height, 3), dtype=np.uint8)\n",
    "\n",
    "    x_offset, y_offset = get_offset(obs)\n",
    "    \n",
    "    # layer reference: https://github.com/cbinners/gym-battlesnake/blob/master/gym_battlesnake/src/gamewrapper.cpp#L132\n",
    "    for x in range(23):\n",
    "        for y in range(23):\n",
    "            # Render snake bodies\n",
    "            if obs[0][1][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset] = 255 - 10*(255 - obs[0][2][x][y])\n",
    "\n",
    "            # layer 4: shared food location\n",
    "            if obs[0][4][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset][0] = 255\n",
    "                output[x-x_offset][y-y_offset][1] = 255 # yellow\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "            \n",
    "            # layer 0: snake health\n",
    "            if obs[0][0][x][y] > 0:\n",
    "                output[x-x_offset][y-y_offset][0] = 255 # red\n",
    "                output[x-x_offset][y-y_offset][1] = 0\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "                \n",
    "                # output[x-x_offset][y-y_offset][3] = obs[0][0][x][y]\n",
    "                \n",
    "            # layer 6: agent's head\n",
    "            if obs[0][6][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset][0] = 0\n",
    "                output[x-x_offset][y-y_offset][1] = 255 # green\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "\n",
    "    return output\n",
    "\n",
    "def simulate_game(policy, frames=300):\n",
    "    playground = BattlesnakeEnv(n_threads=CPU_THREADS, n_envs=1, fixed_orientation=True,\n",
    "                                opponents=policies, device=device)\n",
    "\n",
    "    # Reset the environment \n",
    "    obs = playground.reset()\n",
    "\n",
    "    obs_list = []\n",
    "\n",
    "    # Grab a set of frames to render\n",
    "    with torch.no_grad():\n",
    "        for _ in tqdm(range(frames)):\n",
    "            obs_list.append(copy.deepcopy(obs))\n",
    "\n",
    "            # Get the action our policy should take\n",
    "            _, action, _, _ = policy.act(torch.tensor(obs, dtype=torch.float32).to(device), None, None)\n",
    "            print(action)\n",
    "\n",
    "            # Perform our action and update our observation\n",
    "            obs,_,_,_ = playground.step(action.cpu().squeeze())\n",
    "\n",
    "    return obs_list\n",
    "\n",
    "def visualize_game(obs_list):\n",
    "\n",
    "    # Keep track of game frames to render\n",
    "    video = []\n",
    "\n",
    "    for obs in obs_list:\n",
    "        # Add the rendered observation to our frame stack\n",
    "        video.append(obs_to_frame(obs))\n",
    "\n",
    "    # Render, adapted from here: https://stackoverflow.com/questions/57060422/fast-way-to-display-video-from-arrays-in-jupyter-lab\n",
    "    video = np.array(video, dtype=np.uint8)\n",
    "    # fig = plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    im = ax.imshow(video[0,:,:,:])\n",
    "\n",
    "    def init():\n",
    "        im.set_data(video[0,:,:,:])\n",
    "\n",
    "    def animate(i):\n",
    "        for txt in ax.texts:\n",
    "            txt.remove()\n",
    "        im.set_data(video[i,:,:,:])\n",
    "\n",
    "        obs = obs_list[i]\n",
    "        x_offset, y_offset = get_offset(obs)\n",
    "        print(f'x_offset: {x_offset}, y_offset: {y_offset}')\n",
    "        \n",
    "        layer = 2\n",
    "        for x in range(23):\n",
    "            for y in range(23):\n",
    "                text = ''\n",
    "                if obs[0][2][x][y] > 0:\n",
    "                    text = obs[0][layer][x][y]\n",
    "                ax.text(y-y_offset, x-x_offset, text,\n",
    "                    ha=\"center\", va=\"center\", color=\"w\")\n",
    "        return im\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    anim = animation.FuncAnimation(fig,\n",
    "                                   animate, init_func=init,\n",
    "                                   frames=video.shape[0],\n",
    "                                   interval=200 # milliseconds per frame\n",
    "                                   )\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5686ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "u.set_modelgroup('test10', read_tmp=True)\n",
    "model_path = None\n",
    "\n",
    "latest_model_path, cur_iter = u.get_latest_model()\n",
    "print(latest_model_path)\n",
    "if latest_model_path is not None:\n",
    "    model_path = latest_model_path\n",
    "else:\n",
    "    sys.exit(1)\n",
    "\n",
    "print('Loading model from:', model_path)\n",
    "\n",
    "# print(torch.load(model_path))\n",
    "\n",
    "tmp_env = setup_rollouts()\n",
    "policy = setup_policy(tmp_env, model_path=model_path)\n",
    "if policy is None:\n",
    "    print('Policy is None')\n",
    "    sys.exit(1)\n",
    "\n",
    "policies = [policy for _ in range(n_opponents)]\n",
    "\n",
    "data = u.load_data(start_iteration=cur_iter)\n",
    "rewards = data['rewards']\n",
    "value_losses = data['value_losses']\n",
    "action_losses = data['action_losses']\n",
    "dist_entropies = data['dist_entropies']\n",
    "lengths = data['lengths']\n",
    "\n",
    "# plot_graphs(rewards, value_losses, action_losses, dist_entropies, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cba7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_list = simulate_game(policy, frames=1000)\n",
    "obs_list = simulate_game(policy, frames=10)\n",
    "anim = visualize_game(obs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e70a6-d1a4-41b3-8dfb-b0008cddfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: automate finding next best model(s)\n",
    "models_to_test = [\n",
    "    # 'models/test10/tmp_iter3000.pt',\n",
    "    # 'models/test10/tmp_iter2800.pt',\n",
    "    # 'models/test10/tmp_iter2600.pt',\n",
    "    # 'models/test10/tmp_iter2400.pt',\n",
    "    # 'models/test10/tmp_iter2200.pt',\n",
    "    # 'models/test10/tmp_iter2000.pt',\n",
    "    # 'models/test10/tmp_iter1800.pt',\n",
    "    # 'models/test10/tmp_iter1600.pt',\n",
    "    # 'models/test10/tmp_iter1400.pt',\n",
    "    # 'models/test10/tmp_iter1200.pt',\n",
    "    # 'models/test10/tmp_iter1000.pt',\n",
    "    # 'models/test10/tmp_iter800.pt',\n",
    "    # 'models/test10/tmp_iter600.pt',\n",
    "]\n",
    "\n",
    "def regression_test():\n",
    "    for next_best_modelpath in models_to_test:\n",
    "        print(f'Testing {next_best_modelpath}')\n",
    "        next_best_policy = setup_policy(tmp_env, model_path=next_best_modelpath)\n",
    "        winrate = check_performance(policy, next_best_policy, device=torch.device(device))\n",
    "        \n",
    "        print(f'Winrate: {winrate}')\n",
    "\n",
    "# regression_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
