{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from bs_gym.gymbattlesnake import BattlesnakeEnv\n",
    "from a2c_ppo_acktr.storage import RolloutStorage\n",
    "\n",
    "from policy import SnakePolicyBase, create_policy\n",
    "from utils import PathHelper\n",
    "# from utils import device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: CONFIG FILE\n",
    "n_envs = 1\n",
    "n_steps = 600\n",
    "\n",
    "# torch.backends.cuda.matmul.allow_tf32 = False # Do matmul at TF32 mode.\n",
    "CPU_THREADS = os.cpu_count()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "MODEL_GROUP = 'test10'\n",
    "\n",
    "NUM_LAYERS = 17\n",
    "LAYER_WIDTH = 23\n",
    "LAYER_HEIGHT = 23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logger\n",
    "logger = logging.getLogger('inference')\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.DEBUG)\n",
    "stdout_handler.setFormatter(formatter)\n",
    "logger.addHandler(stdout_handler)\n",
    "\n",
    "\n",
    "# get latest model\n",
    "MODEL_PATH = None\n",
    "u = PathHelper()\n",
    "u.set_modelgroup(MODEL_GROUP, read_tmp=True)\n",
    "MODEL_PATH, _ = u.get_latest_model()\n",
    "\n",
    "print('Loading model from:', MODEL_PATH)\n",
    "\n",
    "if MODEL_PATH is None:\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_env = BattlesnakeEnv(n_threads=CPU_THREADS, n_envs=n_envs)\n",
    "tmp_env.close()\n",
    "\n",
    "# Load policy\n",
    "policy = create_policy(tmp_env.observation_space.shape, tmp_env.action_space, SnakePolicyBase)\n",
    "policy.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "policy.to(device)\n",
    "policy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from bs_gym.gymbattlesnake import BattlesnakeEnv\n",
    "\n",
    "import sys\n",
    "import copy\n",
    "def get_offset(obs):\n",
    "    for x in range(23):\n",
    "        for y in range(23):\n",
    "            if obs[0][5][x][y] == 1:\n",
    "                return x, y\n",
    "\n",
    "\n",
    "def obs_to_frame(obs, width=11, height=11):\n",
    "    output = np.zeros((width, height, 3), dtype=np.uint8)\n",
    "\n",
    "    x_offset, y_offset = get_offset(obs)\n",
    "    \n",
    "    # layer reference: https://github.com/cbinners/gym-battlesnake/blob/master/gym_battlesnake/src/gamewrapper.cpp#L132\n",
    "    for x in range(23):\n",
    "        for y in range(23):\n",
    "            # Render snake bodies\n",
    "            if obs[0][1][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset] = 255 - 10*(255 - obs[0][2][x][y])\n",
    "\n",
    "            # layer 4: shared food location\n",
    "            if obs[0][4][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset][0] = 255\n",
    "                output[x-x_offset][y-y_offset][1] = 255 # yellow\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "            \n",
    "            # layer 0: snake health\n",
    "            if obs[0][0][x][y] > 0:\n",
    "                output[x-x_offset][y-y_offset][0] = 255 # red\n",
    "                output[x-x_offset][y-y_offset][1] = 0\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "                \n",
    "                # output[x-x_offset][y-y_offset][3] = obs[0][0][x][y]\n",
    "                \n",
    "            # layer 6: agent's head\n",
    "            if obs[0][6][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset][0] = 0\n",
    "                output[x-x_offset][y-y_offset][1] = 255 # green\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "\n",
    "    return output\n",
    "\n",
    "def visualize_game(obs_list):\n",
    "\n",
    "    # Keep track of game frames to render\n",
    "    video = []\n",
    "\n",
    "    for obs in obs_list:\n",
    "        # Add the rendered observation to our frame stack\n",
    "        video.append(obs_to_frame(obs))\n",
    "\n",
    "    # Render, adapted from here: https://stackoverflow.com/questions/57060422/fast-way-to-display-video-from-arrays-in-jupyter-lab\n",
    "    video = np.array(video, dtype=np.uint8)\n",
    "    # fig = plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    im = ax.imshow(video[0,:,:,:])\n",
    "\n",
    "    def init():\n",
    "        im.set_data(video[0,:,:,:])\n",
    "\n",
    "    def animate(i):\n",
    "        for txt in ax.texts:\n",
    "            txt.remove()\n",
    "        im.set_data(video[i,:,:,:])\n",
    "\n",
    "        obs = obs_list[i]\n",
    "        x_offset, y_offset = get_offset(obs)\n",
    "        print(f'x_offset: {x_offset}, y_offset: {y_offset}')\n",
    "        \n",
    "        layer = 2\n",
    "        for x in range(23):\n",
    "            for y in range(23):\n",
    "                text = ''\n",
    "                if obs[0][2][x][y] > 0:\n",
    "                    text = obs[0][layer][x][y]\n",
    "                ax.text(y-y_offset, x-x_offset, text,\n",
    "                    ha=\"center\", va=\"center\", color=\"w\")\n",
    "        return im\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    anim = animation.FuncAnimation(fig,\n",
    "                                   animate, init_func=init,\n",
    "                                   frames=video.shape[0],\n",
    "                                   interval=200 # milliseconds per frame\n",
    "                                   )\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start server to accept inference requests\n",
    "from fastapi import FastAPI\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import time\n",
    "app = FastAPI()\n",
    "\n",
    "class InferenceRequest(BaseModel):\n",
    "    id: str\n",
    "    width: int\n",
    "    height: int\n",
    "    input: 'Frames'\n",
    "\n",
    "class Frames(BaseModel):\n",
    "    l0_health: List[List[int]]\n",
    "    l1_bodies: List[List[int]]\n",
    "    l2_segments: List[List[int]]\n",
    "    l3_snake_length: List[List[int]]\n",
    "    l4_food: List[List[int]]\n",
    "    l5_board: List[List[int]]\n",
    "    l6_head_mask: List[List[int]]\n",
    "    l7_tail_mask: List[List[int]]\n",
    "    l8_bodies_gte: List[List[int]]\n",
    "    l9_bodies_lt: List[List[int]]\n",
    "    alive_count: List[List[List[int]]] # 7 layers\n",
    "\n",
    "InferenceRequest.model_rebuild()\n",
    "\n",
    "obss = []\n",
    "\n",
    "@app.post(\"/api/predict\")\n",
    "def predict(req: InferenceRequest):\n",
    "    # TODO: logging with UUID\n",
    "    # TODO: time inference\n",
    "\n",
    "    id = req.id\n",
    "    # width = req.width\n",
    "    # height = req.height\n",
    "    frames = req.input\n",
    "\n",
    "    # create observation\n",
    "    # obs = np.zeros(shape=(n_envs, NUM_LAYERS, LAYER_WIDTH, LAYER_HEIGHT), dtype=np.uint8)\n",
    "    array = [\n",
    "        [\n",
    "        frames.l0_health,\n",
    "        frames.l1_bodies,\n",
    "        frames.l2_segments,\n",
    "        frames.l3_snake_length,\n",
    "        frames.l4_food,\n",
    "        frames.l5_board,\n",
    "        frames.l6_head_mask,\n",
    "        frames.l7_tail_mask,\n",
    "        frames.l8_bodies_gte,\n",
    "        frames.l9_bodies_lt,\n",
    "        *frames.alive_count,\n",
    "        ]\n",
    "    ]\n",
    "    obs = np.asarray(array, dtype=np.uint8)\n",
    "    obss.append(obs)\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    # execute interence on environment\n",
    "    with torch.no_grad():\n",
    "\n",
    "        inp = torch.tensor(obs, dtype=torch.float32).to(device)\n",
    "        action, value = policy.predict(inp, deterministic=True)\n",
    "\n",
    "    # bench time\n",
    "    endTime = time.time()\n",
    "    logger.info(f\"Inference took {endTime - startTime} seconds for {id}\")\n",
    "\n",
    "    # convert pytorch tensor to numpy integer\n",
    "    flattened_action:np.array = action.cpu().numpy().flatten()\n",
    "    flattened_value = value.cpu().numpy().flatten()\n",
    "    if flattened_action.shape != (1,) or flattened_value.shape != (1,):\n",
    "        logger.error(f\"Invalid action or value shape: {flattened_action.shape}, {flattened_value.shape}\")\n",
    "        return {\n",
    "            \"action\": -1,\n",
    "            \"value\": 0.0,\n",
    "            \"error\": \"Invalid action or value shape\",\n",
    "        }\n",
    "    if flattened_action[0] not in [0, 1, 2, 3]:\n",
    "        return {\n",
    "            \"action\": -1,\n",
    "            \"value\": 0.0,\n",
    "            \"error\": \"Unexpected network output\",\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"action\": int(flattened_action[0]),\n",
    "        \"value\": int(flattened_value[0]),\n",
    "        \"error\": \"\",\n",
    "    }\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "import nest_asyncio\n",
    "import uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "obss = []\n",
    "nest_asyncio.apply()\n",
    "\n",
    "uvicorn.run(app, host='0.0.0.0', port=7801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obss[3]\n",
    "# print all frames\n",
    "for f in range(17):\n",
    "    print('i=', f)\n",
    "    print(obs[0][f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anim = visualize_game(obss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
