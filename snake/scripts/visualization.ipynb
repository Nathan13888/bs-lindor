{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea547e20",
   "metadata": {},
   "source": [
    "# Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08e7f5-9674-4f7f-8f4d-ef05b45cb10b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from bs_gym.gymbattlesnake import BattlesnakeEnv\n",
    "from a2c_ppo_acktr.storage import RolloutStorage\n",
    "\n",
    "from policy import SnakePolicyBase, create_policy\n",
    "from utils import n_opponents, device\n",
    "from utils import PathHelper, plot_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a297b1f-a5a6-4590-8d7b-c1728b6d1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u = PathHelper()\n",
    "rollouts = None\n",
    "policy = None\n",
    "policies = None\n",
    "\n",
    "# TODO:\n",
    "n_envs = 1\n",
    "n_steps = 600\n",
    "CPU_THREADS = 6\n",
    "\n",
    "\n",
    "def setup_env(model_path):\n",
    "    global rollouts, policy, policies\n",
    "    tmp_env = BattlesnakeEnv(n_threads=2, n_envs=n_envs)\n",
    "\n",
    "    rollouts = RolloutStorage(n_steps,\n",
    "                            n_envs,\n",
    "                            tmp_env.observation_space.shape,\n",
    "                            tmp_env.action_space,\n",
    "                            n_steps)\n",
    "    tmp_env.close()\n",
    "\n",
    "    policy = create_policy(tmp_env.observation_space.shape, tmp_env.action_space, SnakePolicyBase)\n",
    "    policy.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    policy.to(device)\n",
    "    policy.eval()\n",
    "\n",
    "    policies = [policy for _ in range(n_opponents)]\n",
    "    # TODO: load multiple models, load state dict into policies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8002e-4bdc-4591-8888-09c4676c20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def obs_to_frame(obs):\n",
    "    ''' Converts an environment observation into a renderable RGB image '''\n",
    "    # First, let's find the game board dimensions from layer 5\n",
    "    x_offset, y_offset = 0, 0\n",
    "    done = False\n",
    "    for x in range(23):\n",
    "        if done:\n",
    "            break\n",
    "        for y in range(23):\n",
    "            if obs[0][5][x][y] == 1:\n",
    "                x_offset = x\n",
    "                y_offset = y\n",
    "                done = True\n",
    "                break\n",
    "    output = np.zeros((11, 11, 3), dtype=np.uint8)\n",
    "\n",
    "    # See https://github.com/cbinners/gym-battlesnake/blob/master/gym_battlesnake/src/gamewrapper.cpp#L55 for\n",
    "    # layer reference\n",
    "    # TODO: to improve?\n",
    "    for x in range(23):\n",
    "        for y in range(23):\n",
    "            # Render snake bodies\n",
    "            if obs[0][1][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset] = 255 - 10*(255 - obs[0][2][x][y])\n",
    "            # Render food\n",
    "            if obs[0][4][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset][0] = 255\n",
    "                output[x-x_offset][y-y_offset][1] = 255\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "            # Render snake heads as a red pixel\n",
    "            if obs[0][0][x][y] > 0:\n",
    "                output[x-x_offset][y-y_offset][0] = 255\n",
    "                output[x-x_offset][y-y_offset][1] = 0\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "            # Render snake heads\n",
    "            if obs[0][6][x][y] == 1:\n",
    "                output[x-x_offset][y-y_offset][0] = 0\n",
    "                output[x-x_offset][y-y_offset][1] = 255\n",
    "                output[x-x_offset][y-y_offset][2] = 0\n",
    "\n",
    "    return output\n",
    "\n",
    "def visualize_game(policy):\n",
    "    playground = BattlesnakeEnv(n_threads=CPU_THREADS, n_envs=1, fixed_orientation=True,\n",
    "                                opponents=policies, device=device,\n",
    "                                )\n",
    "\n",
    "    # Reset the environment \n",
    "    obs = playground.reset()\n",
    "\n",
    "    # Keep track of game frames to render\n",
    "    video = []\n",
    "\n",
    "    # Grab a set of frames to render\n",
    "    with torch.no_grad():\n",
    "        for _ in tqdm(range(300)):\n",
    "            # Add the rendered observation to our frame stack\n",
    "            video.append(obs_to_frame(obs))\n",
    "\n",
    "            # Get the action our policy should take\n",
    "            _, action, _, _ = policy.act(torch.tensor(obs, dtype=torch.float32).to(device), None, None)\n",
    "\n",
    "            # Perform our action and update our observation\n",
    "            obs,_,_,_ = playground.step(action.cpu().squeeze())\n",
    "\n",
    "    # Render, adapted from here: https://stackoverflow.com/questions/57060422/fast-way-to-display-video-from-arrays-in-jupyter-lab\n",
    "\n",
    "    video = np.array(video, dtype=np.uint8)\n",
    "    fig = plt.figure()\n",
    "\n",
    "    im = plt.imshow(video[0,:,:,:])\n",
    "    def init():\n",
    "        im.set_data(video[0,:,:,:])\n",
    "    def animate(i):\n",
    "        im.set_data(video[i,:,:,:])\n",
    "        return im\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0], interval=200)\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5686ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.set_modelgroup('test6', read_tmp=True)\n",
    "model_path = None\n",
    "\n",
    "latest_model_path, _ = u.get_latest_model()\n",
    "print(latest_model_path)\n",
    "if latest_model_path is not None:\n",
    "    model_path = latest_model_path\n",
    "\n",
    "print('Loading model from:', model_path)\n",
    "setup_env(model_path)\n",
    "\n",
    "data = u.load_data()\n",
    "rewards = data['rewards']\n",
    "value_losses = data['value_losses']\n",
    "action_losses = data['action_losses']\n",
    "dist_entropies = data['dist_entropies']\n",
    "lengths = data['lengths']\n",
    "\n",
    "print(data)\n",
    "\n",
    "plot_graphs(rewards, value_losses, action_losses, dist_entropies, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e70a6-d1a4-41b3-8dfb-b0008cddfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = visualize_game(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
